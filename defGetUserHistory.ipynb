{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json, requests, pandas, time, re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 PARAMETROS OBLIGATORIOS: MAIL/USERID Y CAMPOS DESEADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# se puede llamar al servicio con emails o tracker ids, en forma de lista\n",
    "emails = [\"patriciatojo@hotmail.com\", \"veronica.seminario@despegar.com\", \"jcorigliano@despegar.com\"]\n",
    "users = ['d7c4c073-ef9a-493f-84c0-73ef9a393f0a', '644ef9f3-204d-4a25-8ef9-f3204d3a25ae']\n",
    "\n",
    "# Campos seleccionados\n",
    "campos = [\"userid\", \"email\", \"datetime\", \"pr\", \"fl\", \"ci\", \"co\", \"dc\", \"pri\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PARAMETROS OPCIONALES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from_date = \"15/05/2016\"\n",
    "start_ts = int(time.mktime(datetime.strptime(from_date, \"%d/%m/%Y\").timetuple())) * 1000\n",
    "\n",
    "to_date = \"10/07/2016\"\n",
    "end_ts = int(time.mktime(datetime.strptime(to_date, \"%d/%m/%Y\").timetuple())) * 1000\n",
    "\n",
    "last_n_obs = \"100\"\n",
    "\n",
    "flows_select = \"SEARCH,DETAIL,CHECKOUT,THANKS\"\n",
    "\n",
    "prods_select = \"FLIGHTS,HOTELS\"\n",
    "\n",
    "brands_select = \"ALL_DESPEGAR\" \n",
    "\n",
    "countries_select = \"AR,BR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcion que llama al servicio y descarga datos del json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getUserHistory(email_or_trackerid):\n",
    "    #WAIT_SECONDS = 0.2\n",
    "    #time.sleep(WAIT_SECONDS)\n",
    "    \n",
    "    userid_format = re.compile('^[a-z0-9]{8}(\\\\-[a-z0-9]{4}){3}\\\\-[a-z0-9]{12}$')\n",
    "    kind = \"user\" if re.search(userid_format, email_or_trackerid) else \"email\"\n",
    "    amount_param = \"amount=\" + last_n_obs if last_n_obs else \"amount=\" + 1000 # por default pido 1000\n",
    "    flow_param = \"&flows=\" + flows_select if flows_select else \"\"\n",
    "    prod_param = \"&products=\" + prods_select if prods_select else \"\"\n",
    "    country_param = \"&countries=\" + countries_select if flows_select else \"\"\n",
    "    brand_param = \"&brands=\" + brands_select if flows_select else \"\"\n",
    "    to_ts_param = \"&to_ts=\" + str(end_ts) if end_ts else \"\"\n",
    "    from_ts_param = \"&from_ts=\" + str(start_ts) if start_ts else \"\"\n",
    "\n",
    "    url = \"http://10.2.7.6/euler-service/v3/\" + kind + \"/\" + email_or_trackerid + \"/history?\" + flow_param + prod_param + country_param + brand_param + from_ts_param + to_ts_param\n",
    "    headers = {'X-Client': 'Vero Analytics', 'X-Cluster': 'euler-web-beta-h2'}\n",
    "    rfm_get = requests.get(url, headers=headers)\n",
    "    return rfm_get.json()\n",
    "\n",
    "# funcion que selecciona solo los campos pedidos y los devuelve como key-value    \n",
    "def selectFields(event, columns):\n",
    "    return {k: event[k] for k in event if str(k) in columns}\n",
    "\n",
    "#for k in event.iterkeys():\n",
    "#        if str(k) in columns:\n",
    "#            return {k: event[k]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplico la función a un RDD de una lista de userids o emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usersRDD = sc.parallelize(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "histories = usersRDD.flatMap(getUserHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "histories.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# en el json, los campos estan adentro de la llave de actionData. \n",
    "# Primero hago flatmap para aplanar el json\n",
    "histories = usersRDD.flatMap(getUserHistory)    .map(lambda event: event['actionData'])    .map(lambda event: selectFields(event, campos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# El problema para pasar de rdd a dataframe con createDataFrame es que inferschema infiere el schema del primer dict, \n",
    "# pero no todos los dict tienen el mismo schema (porque no todos los eventos tienen los mismos campos)\n",
    "sqlContext.createDataFrame(histories).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hago yo el schema, asumiendo que son todos strings\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, DateType, TimestampType,LongType\n",
    "\n",
    "def inferirSchema(campos):\n",
    "    schema_campo = []\n",
    "    for k in campos:\n",
    "        if k in ['hc', 'hr', 'rev', 'utype', 'hc', 'geoid', 'pg', 'days', 'dt', 'nr', 'rn', 'pssgrcount']:\n",
    "            schema_campo.append(StructField(k,  IntegerType(), True))\n",
    "        elif k in ['datetime', 'timestamp', 'hid', 'idcro']:\n",
    "            schema_campo.append(StructField(k, LongType(), False))\n",
    "        else:\n",
    "            schema_campo.append(StructField(k, StringType(), True))\n",
    "    return StructType(schema_campo)\n",
    "\n",
    "schema = inferirSchema(campos)\n",
    "\n",
    "print schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "df = sqlContext.createDataFrame(histories, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create Pandas dataframe\n",
    "\n",
    "historiesPanda = df.toPandas()\n",
    "\n",
    "historiesPanda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### funcion que llama al servicio y descarga datos del json\n",
    "def getUserHistory(userid):\n",
    "    WAIT_SECONDS = 0.2\n",
    "    time.sleep(WAIT_SECONDS)\n",
    "    url = \"http://10.2.7.6/euler-service/v3/user/\" + userid + \"/history/\"\n",
    "    headers = {'X-Client': 'Vero Analytics', 'X-Cluster': 'euler-web-beta-h2'}\n",
    "    rfm_get = requests.get(url, headers=headers)\n",
    "    return rfm_get.json()\n",
    "    \n",
    "# funcion que selecciona solo los campos pedidos y los devuelve como key-value    \n",
    "def selectFields(event, columns):\n",
    "    return {k: event[k] for k in event if str(k) in columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### como funciona match para saber el formato de userid?\n",
    "userid_format = re.compile('^[a-z0-9]{8}(\\\\-[a-z0-9]{4}){3}\\\\-[a-z0-9]{12}$')\n",
    "\n",
    "# si hay match, el objeto existe, si no no.\n",
    "match = re.search(userid_format, 'd7c4c073-ef9a-493f-84c0-73ef9a393f0a')\n",
    "if match:\n",
    "    print 'ok'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### asi hubiera hecho el schema si todos los structype fueran string ¬¬\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(k,  StringType(), True) for k in campos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# es lo mismo que hacer campo por campo\n",
    "#schema = StructType([StructField('userId', StringType(), True),\n",
    "#                     StructField('timestamp', StringType(), True),\n",
    "#                     StructField('pr', StringType(), True),\n",
    "#                     StructField('fl', StringType(), True),\n",
    "#                     StructField('ci', StringType(), True),\n",
    "#                     StructField('co', StringType(), True),\n",
    "#                     StructField('dc', StringType(), True),\n",
    "#                     StructField('pri', StringType(), True)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
